#!/usr/bin/env python
"""
ç­–ç•¥ç½‘ç»œæ‰¹å¤„ç†æµ‹è¯•è„šæœ¬
éªŒè¯ç­–ç•¥ç½‘ç»œå¦‚ä½•å¤„ç†å¤šæ¶é£æœºçš„è¾“å…¥
"""

import numpy as np
import torch
import sys
import os
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

from algorithms.ppo.ppo_actor import PPOActor
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class Args:
    def __init__(self) -> None:
        self.gain = 0.01
        self.hidden_size = '128 128'
        self.act_hidden_size = '128 128'
        self.activation_id = 1
        self.use_feature_normalization = False
        self.use_recurrent_policy = True
        self.recurrent_hidden_size = 128
        self.recurrent_hidden_layers = 1
        self.tpdv = dict(dtype=torch.float32, device=torch.device('cpu'))
        self.use_prior = True

def test_batch_processing():
    """æµ‹è¯•ç­–ç•¥ç½‘ç»œçš„æ‰¹å¤„ç†èƒ½åŠ›"""
    
    logger.info("=" * 60)
    logger.info("ç­–ç•¥ç½‘ç»œæ‰¹å¤„ç†æµ‹è¯•")
    logger.info("=" * 60)
    
    # åˆ›å»ºç­–ç•¥ç½‘ç»œ
    args = Args()
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    # æ¨¡æ‹Ÿè§‚å¯Ÿç©ºé—´å’ŒåŠ¨ä½œç©ºé—´
    from gymnasium.spaces import Box, MultiDiscrete
    obs_space = Box(low=-np.inf, high=np.inf, shape=(15,))
    act_space = MultiDiscrete([41, 41, 41, 30])
    
    policy = PPOActor(args, obs_space, act_space, device=device)
    policy.eval()
    
    logger.info(f"ç­–ç•¥ç½‘ç»œåˆ›å»ºæˆåŠŸï¼Œè®¾å¤‡: {device}")
    
    # æµ‹è¯•1æ¶é£æœºï¼ˆè®­ç»ƒæ—¶çš„æƒ…å†µï¼‰
    logger.info("\n1. æµ‹è¯•1æ¶é£æœºè¾“å…¥:")
    obs_1v1 = np.random.randn(1, 15).astype(np.float32)  # (1, 15)
    rnn_states_1v1 = np.zeros((1, 1, 128), dtype=np.float32)  # (1, 1, 128)
    masks_1v1 = np.ones((1, 1), dtype=np.float32)  # (1, 1)
    
    with torch.no_grad():
        actions_1v1, log_probs_1v1, rnn_out_1v1 = policy(obs_1v1, rnn_states_1v1, masks_1v1, deterministic=True)
    
    logger.info(f"  è¾“å…¥å½¢çŠ¶: {obs_1v1.shape}")
    logger.info(f"  è¾“å‡ºåŠ¨ä½œå½¢çŠ¶: {actions_1v1.shape}")
    logger.info(f"  è¾“å‡ºRNNçŠ¶æ€å½¢çŠ¶: {rnn_out_1v1.shape}")
    
    # æµ‹è¯•4æ¶é£æœºï¼ˆ4v4æ¸²æŸ“æ—¶çš„æƒ…å†µï¼‰
    logger.info("\n2. æµ‹è¯•4æ¶é£æœºè¾“å…¥:")
    obs_4v4 = np.random.randn(4, 15).astype(np.float32)  # (4, 15)
    rnn_states_4v4 = np.zeros((4, 1, 128), dtype=np.float32)  # (4, 1, 128)
    masks_4v4 = np.ones((4, 1), dtype=np.float32)  # (4, 1)
    
    with torch.no_grad():
        actions_4v4, log_probs_4v4, rnn_out_4v4 = policy(obs_4v4, rnn_states_4v4, masks_4v4, deterministic=True)
    
    logger.info(f"  è¾“å…¥å½¢çŠ¶: {obs_4v4.shape}")
    logger.info(f"  è¾“å‡ºåŠ¨ä½œå½¢çŠ¶: {actions_4v4.shape}")
    logger.info(f"  è¾“å‡ºRNNçŠ¶æ€å½¢çŠ¶: {rnn_out_4v4.shape}")
    
    # éªŒè¯è¾“å‡º
    logger.info("\n3. éªŒè¯è¾“å‡º:")
    logger.info(f"  1v1åŠ¨ä½œæ•°é‡: {actions_1v1.shape[0]}")
    logger.info(f"  4v4åŠ¨ä½œæ•°é‡: {actions_4v4.shape[0]}")
    logger.info(f"  4v4åŠ¨ä½œæ˜¯å¦ç‹¬ç«‹: {actions_4v4.shape[0] == 4}")
    
    # æµ‹è¯•åŠ¨ä½œä¸€è‡´æ€§
    logger.info("\n4. æµ‹è¯•åŠ¨ä½œä¸€è‡´æ€§:")
    # ä½¿ç”¨ç›¸åŒçš„è§‚å¯Ÿæ•°æ®
    same_obs = np.random.randn(1, 15).astype(np.float32)
    same_rnn = np.zeros((1, 1, 128), dtype=np.float32)
    same_masks = np.ones((1, 1), dtype=np.float32)
    
    with torch.no_grad():
        action1, _, _ = policy(same_obs, same_rnn, same_masks, deterministic=True)
        action2, _, _ = policy(same_obs, same_rnn, same_masks, deterministic=True)
    
    # åœ¨ç¡®å®šæ€§æ¨¡å¼ä¸‹ï¼Œç›¸åŒè¾“å…¥åº”è¯¥äº§ç”Ÿç›¸åŒè¾“å‡º
    is_consistent = torch.allclose(action1, action2)
    logger.info(f"  ç›¸åŒè¾“å…¥äº§ç”Ÿç›¸åŒè¾“å‡º: {'âœ“' if is_consistent else 'âœ—'}")
    
    # æµ‹è¯•ä¸åŒé£æœºçš„åŠ¨ä½œç‹¬ç«‹æ€§
    logger.info("\n5. æµ‹è¯•åŠ¨ä½œç‹¬ç«‹æ€§:")
    different_obs = np.random.randn(4, 15).astype(np.float32)
    different_rnn = np.zeros((4, 1, 128), dtype=np.float32)
    different_masks = np.ones((4, 1), dtype=np.float32)
    
    with torch.no_grad():
        actions_diff, _, _ = policy(different_obs, different_rnn, different_masks, deterministic=True)
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ä¸åŒçš„åŠ¨ä½œ
    unique_actions = torch.unique(actions_diff, dim=0)
    logger.info(f"  ä¸åŒé£æœºäº§ç”Ÿä¸åŒåŠ¨ä½œ: {'âœ“' if unique_actions.shape[0] > 1 else 'âœ—'}")
    logger.info(f"  å”¯ä¸€åŠ¨ä½œæ•°é‡: {unique_actions.shape[0]}")
    
    logger.info("\n" + "=" * 60)
    logger.info("æ‰¹å¤„ç†æµ‹è¯•å®Œæˆï¼")
    logger.info("=" * 60)
    
    return True

def test_memory_efficiency():
    """æµ‹è¯•å†…å­˜æ•ˆç‡"""
    
    logger.info("\nå†…å­˜æ•ˆç‡æµ‹è¯•:")
    
    args = Args()
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    from gymnasium.spaces import Box, MultiDiscrete
    obs_space = Box(low=-np.inf, high=np.inf, shape=(15,))
    act_space = MultiDiscrete([41, 41, 41, 30])
    
    policy = PPOActor(args, obs_space, act_space, device=device)
    policy.eval()
    
    # æµ‹è¯•ä¸åŒbatch sizeçš„å†…å­˜ä½¿ç”¨
    batch_sizes = [1, 4, 8, 16]
    
    for batch_size in batch_sizes:
        obs = np.random.randn(batch_size, 15).astype(np.float32)
        rnn_states = np.zeros((batch_size, 1, 128), dtype=np.float32)
        masks = np.ones((batch_size, 1), dtype=np.float32)
        
        with torch.no_grad():
            actions, _, _ = policy(obs, rnn_states, masks, deterministic=True)
        
        logger.info(f"  Batch size {batch_size}: è¾“å…¥ {obs.shape}, è¾“å‡º {actions.shape}")

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    
    try:
        # æµ‹è¯•æ‰¹å¤„ç†èƒ½åŠ›
        test_batch_processing()
        
        # æµ‹è¯•å†…å­˜æ•ˆç‡
        test_memory_efficiency()
        
        logger.info("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        logger.info("ç­–ç•¥ç½‘ç»œå®Œå…¨æ”¯æŒä»1æ¶é£æœºåˆ°4æ¶é£æœºçš„æ‰¹å¤„ç†ï¼")
        
    except Exception as e:
        logger.error(f"æµ‹è¯•å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    main() 